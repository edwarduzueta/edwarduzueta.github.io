---
layout: essay
type: essay
title: "Effort Estimation and Tracking Reflection"
date: 2025-12-14
published: true
labels:
  - Software Engineering
  - Agile Development
  - Effort Estimation
  - Project Management
---

When I estimated effort for issues, I didn’t follow a strict formula. Most of my estimates were based on experience, intuition, and comparison to tasks I had already worked on. Before starting an issue, I would read through the requirements and try to picture the full process from start to finish. That usually included understanding what the issue was asking for, thinking through how I would implement it, actually writing the code, and then testing and fixing anything that broke.

A lot of the time, my estimate came from asking myself questions like “Have I done something like this before?” or “How long did the last issue that felt similar take me?” If an issue involved something unfamiliar or vague, I usually estimated higher because I knew I would lose time figuring things out. Even then, I was often wrong, especially on issues that seemed simple at first but turned out to have edge cases or unexpected integration problems.
Did estimating in advance actually help?

Even though my estimates were frequently off, estimating in advance still helped more than I expected. The biggest benefit wasn’t accuracy, but awareness. Having to put a number down forced me to slow down and really think about the scope of the issue instead of assuming it would be quick.

There were several times where, during estimation, I realized a task involved more steps than I initially thought. That changed how I approached the work and sometimes pushed me to start earlier than I otherwise would have. Looking back, even bad estimates were better than no estimates because they gave me a rough sense of which issues were likely to become time sinks.
Was tracking actual effort useful?

Tracking actual effort was honestly eye-opening. There were multiple cases where I thought I had spent “about an hour” on something, but when I actually tracked it, the time was closer to two or three hours. Debugging, in particular, took much longer than I expected, especially when problems weren’t obvious right away.

Seeing the actual numbers made it clear that my intuition about time wasn’t always reliable. Over time, this helped me adjust future estimates and accept that certain types of work, like debugging or integrating features, almost always take longer than planned. It also helped me recognize when I was stuck and spending too much time on a single issue.
How I tracked my effort and how accurate it was

For coding effort, I tracked time spent actively working on code, including writing, debugging, testing, and refactoring. When I used AI tools to help with code, I counted the time spent crafting prompts, reviewing outputs, fixing mistakes, and integrating the results as coding effort. If the AI output didn’t work as expected, the extra time spent correcting it was also included.

Non-coding effort was harder to track. This included time spent reading requirements, planning approaches, researching solutions, writing documentation, and updating issue status. To avoid guessing, I recorded start and stop times for these activities outside of coding. While this wasn’t perfectly precise, it was much more accurate than trying to remember everything at the end.

Overall, I believe my tracking was reasonably accurate. Some short interruptions probably weren’t captured perfectly, but the effort data reflects real work rather than estimates or fabricated numbers.
What I would change next time

If I were doing this again, I would break issues down more aggressively before estimating. Larger issues almost always hid more work than expected, while smaller, well-defined tasks were easier to estimate and track. I would also start tracking non-coding effort more consistently from the very beginning instead of refining my approach partway through the project.

Another thing I would change is reviewing my past estimates earlier and more often. Seeing how far off I was sooner would have helped me adjust my estimating habits earlier in the project instead of learning those lessons near the end.
AI use during estimation and tracking

I did use AI tools during the project, mostly as a support tool rather than a replacement for my own work.

AI tools used:
ChatGPT (OpenAI) – large language model

I used AI to help explain concepts, brainstorm approaches, debug code, and occasionally generate starting points for code or documentation. When using AI for coding-related tasks, I counted the time spent writing prompts, reviewing the responses, testing the output, and fixing errors as coding effort. In practice, this often took longer than expected because AI-generated code rarely worked perfectly without adjustments.

When AI was used for non-coding tasks like understanding requirements or thinking through design decisions, that time was tracked as non-coding effort.

Most AI outputs required edits or verification before being usable. I treated AI responses as suggestions rather than final answers, and I made sure to review everything carefully before integrating it into the project.
Final reflection

This experience showed me that effort estimation isn’t about being right, but about being honest and paying attention. My estimates were often wrong, but tracking real effort helped me understand where my time actually went and why. The process made me more aware of how I work, especially how easily small tasks turn into larger ones. Even though the tracking took extra effort, it gave me a clearer picture of my development process, which is something I can carry into future projects.

Edited locally as part of ICS 314 – Experience 57B.

Note: I used ChatGPT to help with organization and formatting, but the content reflects my own experience and effort during the project.
